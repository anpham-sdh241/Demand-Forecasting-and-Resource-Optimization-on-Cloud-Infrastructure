{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid Prophet + LSTM Training\n",
        "\n",
        "Notebook này huấn luyện mô hình lai giữa Facebook Prophet và LSTM để dự báo `memory_usage_pct`, `cpu_total_usage`, `system_load`. Quy trình:\n",
        "\n",
        "1. Prophet mô hình hóa xu hướng + seasonality trên chuỗi train.\n",
        "2. Sai số (residuals) trên phần train được dùng để huấn luyện LSTM nhằm học các mẫu phi tuyến phức tạp mà Prophet chưa giải thích được.\n",
        "3. Trong giai đoạn dự báo, Prophet dự đoán trước, LSTM dự báo residual tương lai theo kiểu autoregressive, cuối cùng cộng lại tạo thành dự báo hybrid.\n",
        "\n",
        "> **Lưu ý**: Cần cài thêm `prophet` (hoặc `fbprophet` tùy môi trường) và `torch` trước khi chạy notebook này.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Libraries imported\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from prophet import Prophet\n",
        "\n",
        "from model_utils import (\n",
        "    calculate_metrics,\n",
        "    print_metrics,\n",
        "    save_results,\n",
        "    save_model,\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', lambda x: f\"{x:,.6f}\")\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"✓ Libraries imported\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models dir: C:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\models\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "DATA_DIR = Path('processed_data')\n",
        "MODELS_DIR = Path('models')\n",
        "RESULTS_FILE = Path('results_hybrid_prophet_lstm.json')\n",
        "TARGETS = ['memory_usage_pct', 'cpu_total_usage', 'system_load']\n",
        "\n",
        "# Time axis assumptions (30s cadence như các notebook khác)\n",
        "SERIES_FREQ = '30S'\n",
        "START_TIMESTAMP = pd.Timestamp('2024-01-01 00:00:00')\n",
        "\n",
        "# Prophet config\n",
        "PROPHET_CONFIG = {\n",
        "    'seasonality_mode': 'additive',\n",
        "    'weekly_seasonality': True,\n",
        "    'daily_seasonality': True,\n",
        "    'yearly_seasonality': False,\n",
        "    'changepoint_prior_scale': 0.05,\n",
        "}\n",
        "\n",
        "# LSTM residual config\n",
        "WINDOW_SIZE = 48  # 24 phút nếu data mỗi 30 giây\n",
        "HIDDEN_SIZE = 64\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "MODELS_DIR.mkdir(exist_ok=True)\n",
        "print(f\"Models dir: {MODELS_DIR.resolve()}\")\n",
        "print(f\"Device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory_usage_pct: train=68,599 | test=17,150\n",
            "cpu_total_usage: train=68,599 | test=17,150\n",
            "system_load: train=68,599 | test=17,150\n",
            "\n",
            "✓ Series loaded\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "\n",
        "def load_target_series(target: str):\n",
        "    train_path = DATA_DIR / target / 'y_train.csv'\n",
        "    test_path = DATA_DIR / target / 'y_test.csv'\n",
        "    y_train = pd.read_csv(train_path).squeeze()\n",
        "    y_test = pd.read_csv(test_path).squeeze()\n",
        "    return y_train, y_test\n",
        "\n",
        "\n",
        "datasets = {}\n",
        "for target in TARGETS:\n",
        "    y_train, y_test = load_target_series(target)\n",
        "    datasets[target] = {\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'n_train': len(y_train),\n",
        "        'n_test': len(y_test),\n",
        "    }\n",
        "    print(f\"{target}: train={len(y_train):,} | test={len(y_test):,}\")\n",
        "\n",
        "print(\"\\n✓ Series loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "\n",
        "class ResidualDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.X = torch.tensor(sequences, dtype=torch.float32).unsqueeze(-1)\n",
        "        self.y = torch.tensor(targets, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "class LSTMResidualModel(nn.Module):\n",
        "    def __init__(self, hidden_size=64, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=1,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "def build_time_index(length: int, freq: str = SERIES_FREQ, start_ts: pd.Timestamp = START_TIMESTAMP):\n",
        "    return pd.date_range(start=start_ts, periods=length, freq=freq)\n",
        "\n",
        "\n",
        "def create_sequences(values: np.ndarray, window_size: int):\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(values)):\n",
        "        X.append(values[i - window_size:i])\n",
        "        y.append(values[i])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def train_lstm(model, dataloader, epochs, lr):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.train()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_loss = 0.0\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(X_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * len(X_batch)\n",
        "        epoch_loss /= len(dataloader.dataset)\n",
        "        if epoch % 5 == 0 or epoch == 1 or epoch == epochs:\n",
        "            print(f\"    Epoch {epoch:02d}/{epochs} - loss: {epoch_loss:.6f}\")\n",
        "\n",
        "\n",
        "def predict_sequences(model, sequences):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(sequences, dtype=torch.float32).unsqueeze(-1).to(DEVICE)\n",
        "        preds = model(X).cpu().numpy().flatten()\n",
        "    return preds\n",
        "\n",
        "\n",
        "def forecast_residuals(model, seed_sequence, n_steps):\n",
        "    \"\"\"Autoregressive residual forecast using last WINDOW_SIZE scaled residuals.\"\"\"\n",
        "    model.eval()\n",
        "    seq = seed_sequence.copy().tolist()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_steps):\n",
        "            window = torch.tensor(seq[-WINDOW_SIZE:], dtype=torch.float32).view(1, WINDOW_SIZE, 1).to(DEVICE)\n",
        "            pred = model(window).cpu().item()\n",
        "            preds.append(pred)\n",
        "            seq.append(pred)\n",
        "    return np.array(preds)\n",
        "\n",
        "\n",
        "def inverse_scale(values, mean, std):\n",
        "    return values * std + mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "CmdStan installataion missing makefile, path c:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\stan_model\\cmdstan-2.33.1 is invalid. You may wish to re-install cmdstan by running command \"install_cmdstan --overwrite\", or Python code \"import cmdstanpy; cmdstanpy.install_cmdstan(overwrite=True)\"",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m m = \u001b[43mProphet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mPROPHET_CONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstan_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCMDSTANPY\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOK\u001b[39m\u001b[33m\"\u001b[39m, m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\forecaster.py:155\u001b[39m, in \u001b[36mProphet.__init__\u001b[39m\u001b[34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.fit_kwargs = {}\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.validate_inputs()\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_stan_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstan_backend\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\forecaster.py:166\u001b[39m, in \u001b[36mProphet._load_stan_backend\u001b[39m\u001b[34m(self, stan_backend)\u001b[39m\n\u001b[32m    164\u001b[39m             logger.debug(\u001b[33m\"\u001b[39m\u001b[33mUnable to load backend \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m), trying the next one\u001b[39m\u001b[33m\"\u001b[39m, i.name, e)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28mself\u001b[39m.stan_backend = \u001b[43mStanBackendEnum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_backend_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstan_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.stan_backend.get_type())\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\models.py:94\u001b[39m, in \u001b[36mCmdStanPyBackend.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     92\u001b[39m local_cmdstan = importlib_resources.files(\u001b[33m\"\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[33m\"\u001b[39m\u001b[33mstan_model\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcmdstan-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.CMDSTAN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_cmdstan.exists():\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[43mcmdstanpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_cmdstan_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlocal_cmdstan\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\cmdstanpy\\utils\\cmdstan.py:164\u001b[39m, in \u001b[36mset_cmdstan_path\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcmdstan_path\u001b[39m() -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    161\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[33;03m    Validate, then return CmdStan directory path.\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     cmdstan = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mCMDSTAN\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os.environ[\u001b[33m'\u001b[39m\u001b[33mCMDSTAN\u001b[39m\u001b[33m'\u001b[39m]) > \u001b[32m0\u001b[39m:\n\u001b[32m    166\u001b[39m         cmdstan = os.environ[\u001b[33m'\u001b[39m\u001b[33mCMDSTAN\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\cmdstanpy\\utils\\cmdstan.py:138\u001b[39m, in \u001b[36mvalidate_cmdstan_path\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNo CmdStan directory, path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(os.path.join(path, \u001b[33m'\u001b[39m\u001b[33mbin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstanc\u001b[39m\u001b[33m'\u001b[39m + EXTENSION)):\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCmdStan installataion missing binaries in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/bin. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    139\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRe-install cmdstan by running command \u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstall_cmdstan \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    140\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m--overwrite\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, or Python code \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimport cmdstanpy; \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    141\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcmdstanpy.install_cmdstan(overwrite=True)\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    142\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: CmdStan installataion missing makefile, path c:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\stan_model\\cmdstan-2.33.1 is invalid. You may wish to re-install cmdstan by running command \"install_cmdstan --overwrite\", or Python code \"import cmdstanpy; cmdstanpy.install_cmdstan(overwrite=True)\""
          ]
        }
      ],
      "source": [
        "m = Prophet(**PROPHET_CONFIG, stan_backend='CMDSTANPY')\n",
        "print(\"OK\", m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Target: memory_usage_pct\n",
            "================================================================================\n",
            "Training Prophet...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Prophet' object has no attribute 'stan_backend'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining Prophet...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m prophet_start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m prophet = \u001b[43mProphet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mPROPHET_CONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m prophet.fit(train_df)\n\u001b[32m     26\u001b[39m prophet_time = time.time() - prophet_start\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\forecaster.py:155\u001b[39m, in \u001b[36mProphet.__init__\u001b[39m\u001b[34m(self, growth, changepoints, n_changepoints, changepoint_range, yearly_seasonality, weekly_seasonality, daily_seasonality, holidays, seasonality_mode, seasonality_prior_scale, holidays_prior_scale, changepoint_prior_scale, mcmc_samples, interval_width, uncertainty_samples, stan_backend, scaling, holidays_mode)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28mself\u001b[39m.fit_kwargs = {}\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.validate_inputs()\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_stan_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstan_backend\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AnPham\\Documents\\PROJECTS\\Intern1\\.venv\\Lib\\site-packages\\prophet\\forecaster.py:168\u001b[39m, in \u001b[36mProphet._load_stan_backend\u001b[39m\u001b[34m(self, stan_backend)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;28mself\u001b[39m.stan_backend = StanBackendEnum.get_backend_class(stan_backend)()\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mLoaded stan backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstan_backend\u001b[49m.get_type())\n",
            "\u001b[31mAttributeError\u001b[39m: 'Prophet' object has no attribute 'stan_backend'"
          ]
        }
      ],
      "source": [
        "hybrid_models = {}\n",
        "training_metadata = {}\n",
        "summary_records = []\n",
        "detailed_results = {}\n",
        "prediction_store = {}\n",
        "\n",
        "for target in TARGETS:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"Target: {target}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    y_train = datasets[target]['y_train'].reset_index(drop=True)\n",
        "    y_test = datasets[target]['y_test'].reset_index(drop=True)\n",
        "    n_train = len(y_train)\n",
        "    n_test = len(y_test)\n",
        "    total_len = n_train + n_test\n",
        "\n",
        "    time_index = build_time_index(total_len)\n",
        "    train_df = pd.DataFrame({'ds': time_index[:n_train], 'y': y_train.values})\n",
        "\n",
        "    # ---- Prophet training ----\n",
        "    print(\"Training Prophet...\")\n",
        "    prophet_start = time.time()\n",
        "    prophet = Prophet(**PROPHET_CONFIG)\n",
        "    prophet.fit(train_df)\n",
        "    prophet_time = time.time() - prophet_start\n",
        "\n",
        "    future_df = prophet.make_future_dataframe(periods=n_test, freq=SERIES_FREQ)\n",
        "    forecast_df = prophet.predict(future_df)\n",
        "    prophet_preds_all = forecast_df['yhat'].values\n",
        "    prophet_train_pred = prophet_preds_all[:n_train]\n",
        "    prophet_test_pred = prophet_preds_all[n_train:]\n",
        "\n",
        "    # ---- Residual prep ----\n",
        "    train_residuals = y_train.values - prophet_train_pred\n",
        "    residual_mean = train_residuals.mean()\n",
        "    residual_std = train_residuals.std() if train_residuals.std() > 0 else 1e-6\n",
        "    residuals_scaled = (train_residuals - residual_mean) / residual_std\n",
        "\n",
        "    if n_train <= WINDOW_SIZE:\n",
        "        raise ValueError(f\"WINDOW_SIZE ({WINDOW_SIZE}) phải nhỏ hơn số mẫu train ({n_train})\")\n",
        "\n",
        "    seq_X, seq_y = create_sequences(residuals_scaled, WINDOW_SIZE)\n",
        "    residual_dataset = ResidualDataset(seq_X, seq_y)\n",
        "    dataloader = DataLoader(residual_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # ---- LSTM training ----\n",
        "    print(\"Training LSTM on residuals...\")\n",
        "    lstm_model = LSTMResidualModel(hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
        "    lstm_start = time.time()\n",
        "    train_lstm(lstm_model, dataloader, epochs=EPOCHS, lr=LEARNING_RATE)\n",
        "    lstm_time = time.time() - lstm_start\n",
        "\n",
        "    # ---- Residual predictions ----\n",
        "    train_pred_scaled = predict_sequences(lstm_model, seq_X)\n",
        "    residual_train_pred = inverse_scale(train_pred_scaled, residual_mean, residual_std)\n",
        "\n",
        "    residual_train_full = prophet_train_pred.copy()\n",
        "    residual_train_full[:WINDOW_SIZE] = prophet_train_pred[:WINDOW_SIZE]\n",
        "    hybrid_train_pred = prophet_train_pred.copy()\n",
        "    hybrid_train_pred[WINDOW_SIZE:] = prophet_train_pred[WINDOW_SIZE:] + residual_train_pred\n",
        "\n",
        "    seed_sequence = residuals_scaled[-WINDOW_SIZE:]\n",
        "    residual_test_scaled = forecast_residuals(lstm_model, seed_sequence, n_test)\n",
        "    residual_test_pred = inverse_scale(residual_test_scaled, residual_mean, residual_std)\n",
        "    hybrid_test_pred = prophet_test_pred + residual_test_pred\n",
        "\n",
        "    # ---- Metrics ----\n",
        "    prophet_metrics = calculate_metrics(y_test.values, prophet_test_pred)\n",
        "    hybrid_metrics = calculate_metrics(y_test.values, hybrid_test_pred)\n",
        "\n",
        "    print(\"Prophet only metrics:\")\n",
        "    print_metrics(prophet_metrics, target + ' (Prophet)')\n",
        "    print(\"Hybrid metrics:\")\n",
        "    print_metrics(hybrid_metrics, target + ' (Hybrid)')\n",
        "\n",
        "    # ---- Save model package ----\n",
        "    hybrid_package = {\n",
        "        'prophet': prophet,\n",
        "        'lstm_state_dict': lstm_model.state_dict(),\n",
        "        'residual_mean': residual_mean,\n",
        "        'residual_std': residual_std,\n",
        "        'window_size': WINDOW_SIZE,\n",
        "        'freq': SERIES_FREQ,\n",
        "        'start_timestamp': START_TIMESTAMP.isoformat(),\n",
        "        'config': {\n",
        "            'prophet': PROPHET_CONFIG,\n",
        "            'lstm': {\n",
        "                'hidden_size': HIDDEN_SIZE,\n",
        "                'num_layers': NUM_LAYERS,\n",
        "                'dropout': DROPOUT,\n",
        "                'epochs': EPOCHS,\n",
        "                'batch_size': BATCH_SIZE,\n",
        "                'learning_rate': LEARNING_RATE,\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    model_path = save_model(\n",
        "        hybrid_package,\n",
        "        model_name='hybrid_prophet_lstm',\n",
        "        target=target,\n",
        "        config={\n",
        "            'prophet': PROPHET_CONFIG,\n",
        "            'lstm': {\n",
        "                'hidden_size': HIDDEN_SIZE,\n",
        "                'num_layers': NUM_LAYERS,\n",
        "                'dropout': DROPOUT,\n",
        "                'epochs': EPOCHS,\n",
        "                'batch_size': BATCH_SIZE,\n",
        "                'learning_rate': LEARNING_RATE,\n",
        "                'window_size': WINDOW_SIZE,\n",
        "            }\n",
        "        },\n",
        "        models_dir=str(MODELS_DIR)\n",
        "    )\n",
        "\n",
        "    training_metadata[target] = {\n",
        "        'prophet_time_s': prophet_time,\n",
        "        'lstm_time_s': lstm_time,\n",
        "        'model_path': model_path,\n",
        "    }\n",
        "\n",
        "    summary_records.append({\n",
        "        'target': target,\n",
        "        'prophet_mae': prophet_metrics['mae'],\n",
        "        'prophet_rmse': prophet_metrics['rmse'],\n",
        "        'prophet_r2': prophet_metrics['r2'],\n",
        "        'hybrid_mae': hybrid_metrics['mae'],\n",
        "        'hybrid_rmse': hybrid_metrics['rmse'],\n",
        "        'hybrid_r2': hybrid_metrics['r2'],\n",
        "        'prophet_time_s': prophet_time,\n",
        "        'lstm_time_s': lstm_time,\n",
        "        'model_path': model_path,\n",
        "    })\n",
        "\n",
        "    detailed_results[target] = {\n",
        "        'prophet_metrics': prophet_metrics,\n",
        "        'hybrid_metrics': hybrid_metrics,\n",
        "        'prophet_time_s': prophet_time,\n",
        "        'lstm_time_s': lstm_time,\n",
        "        'model_path': model_path,\n",
        "    }\n",
        "\n",
        "    prediction_store[target] = {\n",
        "        'y_train': y_train.values,\n",
        "        'y_test': y_test.values,\n",
        "        'prophet_train': prophet_train_pred,\n",
        "        'prophet_test': prophet_test_pred,\n",
        "        'hybrid_train': hybrid_train_pred,\n",
        "        'hybrid_test': hybrid_test_pred,\n",
        "    }\n",
        "\n",
        "print(\"\\n✓ Training completed for all targets\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_df = pd.DataFrame(summary_records).set_index('target')\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(TARGETS), 1, figsize=(16, 12), sharex=False)\n",
        "fig.suptitle('Hybrid Prophet + LSTM vs Actual (Test Set)', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, target in enumerate(TARGETS):\n",
        "    ax = axes[idx]\n",
        "    data = prediction_store[target]\n",
        "    ax.plot(data['y_test'], label='Actual', alpha=0.7)\n",
        "    ax.plot(data['prophet_test'], label='Prophet', alpha=0.7)\n",
        "    ax.plot(data['hybrid_test'], label='Hybrid', linewidth=2)\n",
        "    ax.set_title(target)\n",
        "    ax.set_ylabel('Normalized value')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    if idx == len(TARGETS) - 1:\n",
        "        ax.set_xlabel('Time step (test)')\n",
        "    if idx == 0:\n",
        "        ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, len(TARGETS), figsize=(18, 5))\n",
        "fig.suptitle('Predicted vs Actual (Hybrid)', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, target in enumerate(TARGETS):\n",
        "    ax = axes[idx]\n",
        "    data = prediction_store[target]\n",
        "    y_true = data['y_test']\n",
        "    y_pred = data['hybrid_test']\n",
        "    ax.scatter(y_true, y_pred, alpha=0.3, s=10)\n",
        "    min_v = min(y_true.min(), y_pred.min())\n",
        "    max_v = max(y_true.max(), y_pred.max())\n",
        "    ax.plot([min_v, max_v], [min_v, max_v], 'r--', linewidth=1)\n",
        "    ax.set_title(f\"{target}\")\n",
        "    ax.set_xlabel('Actual')\n",
        "    ax.set_ylabel('Predicted')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "metrics_df = summary_df[[\n",
        "    'prophet_mae', 'prophet_rmse', 'prophet_r2',\n",
        "    'hybrid_mae', 'hybrid_rmse', 'hybrid_r2'\n",
        "]].copy()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "fig.suptitle('Metrics Comparison (Prophet vs Hybrid)', fontsize=16, fontweight='bold')\n",
        "\n",
        "metrics_df[['prophet_mae', 'hybrid_mae']].plot(kind='bar', ax=axes[0, 0], color=['#90caf9', '#1e88e5'])\n",
        "axes[0, 0].set_title('MAE (lower better)')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "metrics_df[['prophet_rmse', 'hybrid_rmse']].plot(kind='bar', ax=axes[0, 1], color=['#ffab91', '#d84315'])\n",
        "axes[0, 1].set_title('RMSE (lower better)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "metrics_df[['prophet_r2', 'hybrid_r2']].plot(kind='bar', ax=axes[1, 0], color=['#c5e1a5', '#7cb342'])\n",
        "axes[1, 0].set_title('R² (higher better)')\n",
        "axes[1, 0].axhline(0, color='k', linestyle='--', linewidth=1)\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_payload = {\n",
        "    'model': 'hybrid_prophet_lstm',\n",
        "    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'targets': detailed_results,\n",
        "    'training': training_metadata,\n",
        "    'config': {\n",
        "        'prophet': PROPHET_CONFIG,\n",
        "        'lstm': {\n",
        "            'hidden_size': HIDDEN_SIZE,\n",
        "            'num_layers': NUM_LAYERS,\n",
        "            'dropout': DROPOUT,\n",
        "            'epochs': EPOCHS,\n",
        "            'batch_size': BATCH_SIZE,\n",
        "            'learning_rate': LEARNING_RATE,\n",
        "            'window_size': WINDOW_SIZE,\n",
        "        },\n",
        "        'series_freq': SERIES_FREQ,\n",
        "        'start_timestamp': START_TIMESTAMP.isoformat(),\n",
        "    }\n",
        "}\n",
        "\n",
        "save_results(results_payload, str(RESULTS_FILE))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
